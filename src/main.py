"""
Market Rader - ì£¼ì‹ ë‰´ìŠ¤ ë””ìŠ¤ì½”ë“œ ë´‡
ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import sys
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
ROOT_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT_DIR))

from config.settings import settings, get_news_sources, get_youtube_channels
from src.utils.logger import logger
from src.utils.cache import cache

# Collectors
from src.collectors.base import ContentItem, ContentType
from src.collectors.news import (
    NaverFinanceNewsCollector,
    RSSNewsCollector,
    create_rss_collectors,
)
from src.collectors.reports import NaverResearchCollector, SeekingAlphaCollector
from src.collectors.youtube import YouTubeChannelMonitor, transcript_extractor

# Analyzers
from src.analyzer import (
    news_summarizer,
    report_summarizer,
    video_summarizer,
    importance_scorer,
)

# Discord
from src.discord import (
    discord_sender,
    create_news_header_embed,
    create_news_list_embeds,
    create_reports_header_embed,
    create_reports_list_embed,
    create_youtube_header_embed,
    create_youtube_list_embed,
)


def validate_settings() -> bool:
    """ì„¤ì • ê²€ì¦"""
    errors = settings.validate()
    if errors:
        for error in errors:
            logger.error(f"Configuration error: {error}")
        return False
    return True


def collect_news() -> dict:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ (êµ­ë‚´/í•´ì™¸ ë¶„ë¦¬)"""
    logger.info("=== Collecting News ===")
    korean_news = []
    international_news = []

    # 1. ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ (êµ­ë‚´)
    try:
        naver_collector = NaverFinanceNewsCollector(categories=["stock", "economy"])
        naver_news = naver_collector.collect()
        for item in naver_news:
            item.extra_data["region"] = "korean"
        korean_news.extend(naver_news)
        logger.info(f"Naver Finance: {len(naver_news)} items")
    except Exception as e:
        logger.error(f"Naver news collection failed: {e}")

    # 2. RSS ë‰´ìŠ¤
    try:
        news_config = get_news_sources()
        korean_sources = news_config.get("news", {}).get("korean", [])
        intl_sources = news_config.get("news", {}).get("international", [])

        # êµ­ë‚´ RSS
        for source in korean_sources:
            if source.get("type") == "rss" and source.get("enabled", True):
                try:
                    collector = RSSNewsCollector(name=source["name"], url=source["url"])
                    items = collector.collect()
                    for item in items:
                        item.extra_data["region"] = "korean"
                    korean_news.extend(items)
                except Exception as e:
                    logger.warning(f"RSS collection failed for {source.get('name')}: {e}")

        # í•´ì™¸ RSS
        for source in intl_sources:
            if source.get("type") == "rss" and source.get("enabled", True):
                try:
                    collector = RSSNewsCollector(name=source["name"], url=source["url"])
                    items = collector.collect()
                    for item in items:
                        item.extra_data["region"] = "international"
                    international_news.extend(items)
                except Exception as e:
                    logger.warning(f"RSS collection failed for {source.get('name')}: {e}")

    except Exception as e:
        logger.error(f"RSS news collection failed: {e}")

    # ì¤‘ë³µ ì œê±° (ID ê¸°ì¤€)
    def dedupe(news_list):
        seen_ids = set()
        unique = []
        for item in news_list:
            if item.id not in seen_ids and not cache.is_sent(item.id, "news"):
                seen_ids.add(item.id)
                unique.append(item)
        return unique

    korean_news = dedupe(korean_news)
    international_news = dedupe(international_news)

    logger.info(f"Korean news: {len(korean_news)}, International: {len(international_news)}")
    return {"korean": korean_news, "international": international_news}


def collect_reports() -> list[ContentItem]:
    """ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìˆ˜ì§‘"""
    logger.info("=== Collecting Reports ===")
    all_reports = []

    # 1. ë„¤ì´ë²„ ì¦ê¶Œ ë¦¬ì„œì¹˜
    try:
        naver_research = NaverResearchCollector(categories=["invest", "company", "market"])
        reports = naver_research.collect()
        all_reports.extend(reports)
        logger.info(f"Naver Research: {len(reports)} items")
    except Exception as e:
        logger.error(f"Naver research collection failed: {e}")

    # 2. Seeking Alpha
    try:
        sa_collector = SeekingAlphaCollector()
        sa_reports = sa_collector.collect()
        all_reports.extend(sa_reports)
        logger.info(f"Seeking Alpha: {len(sa_reports)} items")
    except Exception as e:
        logger.warning(f"Seeking Alpha collection failed: {e}")

    # ì¤‘ë³µ ì œê±°
    seen_ids = set()
    unique_reports = []
    for item in all_reports:
        if item.id not in seen_ids and not cache.is_sent(item.id, "reports"):
            seen_ids.add(item.id)
            unique_reports.append(item)

    logger.info(f"Total unique reports: {len(unique_reports)}")
    return unique_reports


def collect_youtube() -> dict:
    """ìœ íŠœë¸Œ ì˜ìƒ ìˆ˜ì§‘ (í•œêµ­/í•´ì™¸ ë¶„ë¦¬)"""
    logger.info("=== Collecting YouTube Videos ===")

    try:
        youtube_monitor = YouTubeChannelMonitor()
        videos = youtube_monitor.collect()

        # ì¤‘ë³µ ì œê±° (ì´ë¯¸ ì „ì†¡ëœ ì˜ìƒ ì œì™¸)
        korean_videos = [
            v for v in videos.get("korean", [])
            if not cache.is_sent(v.id, "youtube")
        ]
        intl_videos = [
            v for v in videos.get("international", [])
            if not cache.is_sent(v.id, "youtube")
        ]

        logger.info(f"Total new videos - Korean: {len(korean_videos)}, Intl: {len(intl_videos)}")
        return {"korean": korean_videos, "international": intl_videos}

    except Exception as e:
        logger.error(f"YouTube collection failed: {e}")
        return {"korean": [], "international": []}


def analyze_content(
    news: dict,
    reports: list[ContentItem],
    videos: dict,
) -> dict:
    """ì½˜í…ì¸  ë¶„ì„ ë° ìš”ì•½"""
    logger.info("=== Analyzing Content ===")

    korean_news = news.get("korean", [])
    intl_news = news.get("international", [])
    korean_videos = videos.get("korean", [])
    intl_videos = videos.get("international", [])

    result = {
        "korean_news": korean_news,
        "international_news": intl_news,
        "news_summary": None,
        "reports": reports,
        "reports_summary": None,
        "korean_videos": korean_videos,
        "international_videos": intl_videos,
        "video_summaries": {},
    }

    # 1. êµ­ë‚´ ë‰´ìŠ¤ ì¤‘ìš”ë„ í‰ê°€
    if korean_news:
        scored = importance_scorer.filter_by_importance(korean_news, min_score=0.3)
        result["korean_news"] = scored[:settings.MAX_NEWS_COUNT]

    # 2. í•´ì™¸ ë‰´ìŠ¤ ì¤‘ìš”ë„ í‰ê°€
    if intl_news:
        scored = importance_scorer.filter_by_importance(intl_news, min_score=0.3)
        result["international_news"] = scored[:settings.MAX_NEWS_COUNT]

    # 3. AI ìš”ì•½ (êµ­ë‚´ + í•´ì™¸ í•©ì³ì„œ)
    all_news = result["korean_news"] + result["international_news"]
    if all_news:
        try:
            result["news_summary"] = news_summarizer.summarize_news_batch(all_news[:15])
        except Exception as e:
            logger.warning(f"News summarization failed: {e}")

    # 4. ë¦¬í¬íŠ¸ ì¤‘ìš”ë„ í‰ê°€ - ì¤‘ìš”ë„ ë†’ì€ ìˆœ
    if reports:
        scored_reports = importance_scorer.score_batch(reports)
        scored_reports.sort(key=lambda x: x.importance_score, reverse=True)
        result["reports"] = scored_reports[:settings.MAX_REPORTS_COUNT]
        logger.info(f"Reports top scores: {[f'{r.title[:20]}({r.importance_score})' for r in result['reports'][:5]]}")

        # AI ìš”ì•½
        try:
            result["reports_summary"] = report_summarizer.summarize_reports(
                result["reports"][:10]
            )
        except Exception as e:
            logger.warning(f"Report summarization failed: {e}")

    # 5. ìœ íŠœë¸Œ ì¤‘ìš”ë„ í‰ê°€ ë° ìš”ì•½ (í•œêµ­) - ì¤‘ìš”ë„ ë†’ì€ ìˆœ
    if korean_videos:
        scored = importance_scorer.score_batch(korean_videos)
        scored.sort(key=lambda x: x.importance_score, reverse=True)
        result["korean_videos"] = scored[:5]  # í•œêµ­ 5ê°œ
        logger.info(f"Korean YouTube top scores: {[f'{v.title[:20]}({v.importance_score})' for v in result['korean_videos']]}")

        for video in result["korean_videos"]:
            try:
                summary = video_summarizer.summarize_video(video)
                if summary:
                    result["video_summaries"][video.id] = summary
            except Exception as e:
                logger.warning(f"Video summarization failed for {video.title[:30]}: {e}")

    # 6. ìœ íŠœë¸Œ ì¤‘ìš”ë„ í‰ê°€ ë° ìš”ì•½ (í•´ì™¸) - ì¤‘ìš”ë„ ë†’ì€ ìˆœ
    if intl_videos:
        scored = importance_scorer.score_batch(intl_videos)
        scored.sort(key=lambda x: x.importance_score, reverse=True)
        result["international_videos"] = scored[:5]  # í•´ì™¸ 5ê°œ
        logger.info(f"Intl YouTube top scores: {[f'{v.title[:20]}({v.importance_score})' for v in result['international_videos']]}")

        for video in result["international_videos"]:
            try:
                summary = video_summarizer.summarize_video(video)
                if summary:
                    result["video_summaries"][video.id] = summary
            except Exception as e:
                logger.warning(f"Video summarization failed for {video.title[:30]}: {e}")

    return result


def send_to_discord(analyzed: dict) -> bool:
    """Discordë¡œ ì „ì†¡"""
    logger.info("=== Sending to Discord ===")

    embeds = []
    now = datetime.now()

    korean_news = analyzed.get("korean_news", [])[:10]
    intl_news = analyzed.get("international_news", [])[:10]
    all_news = korean_news + intl_news

    # 1. í—¤ë” (AI ìš”ì•½)
    if all_news:
        header_embed = create_news_header_embed(
            date=now,
            news_count=len(all_news),
            summary=analyzed.get("news_summary"),
        )
        embeds.append(header_embed)

    # 2. êµ­ë‚´ ë‰´ìŠ¤ (10ê±´)
    if korean_news:
        korean_embeds = create_news_list_embeds(
            items=korean_news,
            title=f"ğŸ‡°ğŸ‡· êµ­ë‚´ ë‰´ìŠ¤ ({len(korean_news)}ê±´)",
            items_per_embed=5,
            color="e74c3c",
        )
        embeds.extend(korean_embeds)

    # 3. í•´ì™¸ ë‰´ìŠ¤ (10ê±´)
    if intl_news:
        intl_embeds = create_news_list_embeds(
            items=intl_news,
            title=f"ğŸ‡ºğŸ‡¸ í•´ì™¸ ë‰´ìŠ¤ ({len(intl_news)}ê±´)",
            items_per_embed=5,
            color="3498db",
        )
        embeds.extend(intl_embeds)

    # 4. ë¦¬í¬íŠ¸ (10ê±´)
    reports = analyzed.get("reports", [])[:10]
    if reports:
        reports_header = create_reports_header_embed(
            report_count=len(reports),
            summary=analyzed.get("reports_summary"),
        )
        embeds.append(reports_header)

        reports_list = create_reports_list_embed(
            items=reports,
            max_items=10,
        )
        embeds.append(reports_list)

    # 5. í•œêµ­ ìœ íŠœë¸Œ (5ê±´)
    korean_videos = analyzed.get("korean_videos", [])[:5]
    video_summaries = analyzed.get("video_summaries", {})

    if korean_videos:
        korean_yt_list = create_youtube_list_embed(
            items=korean_videos,
            title=f"ğŸ‡°ğŸ‡· í•œêµ­ ìœ íŠœë¸Œ ({len(korean_videos)}ê±´)",
            max_items=5,
            video_summaries=video_summaries,
        )
        embeds.append(korean_yt_list)

    # 6. í•´ì™¸ ìœ íŠœë¸Œ (5ê±´)
    intl_videos = analyzed.get("international_videos", [])[:5]

    if intl_videos:
        intl_yt_list = create_youtube_list_embed(
            items=intl_videos,
            title=f"ğŸ‡ºğŸ‡¸ í•´ì™¸ ìœ íŠœë¸Œ ({len(intl_videos)}ê±´)",
            max_items=5,
            video_summaries=video_summaries,
        )
        embeds.append(intl_yt_list)

    all_videos = korean_videos + intl_videos

    # Discordë¡œ ì „ì†¡
    if not embeds:
        logger.info("No content to send")
        return True

    success = discord_sender.send_multiple_embeds(
        embeds=embeds,
        username="Market Rader ğŸ“ˆ",
    )

    if success:
        # ìºì‹œì— ì „ì†¡ëœ í•­ëª© ê¸°ë¡
        cache.mark_multiple_as_sent([n.id for n in all_news], "news")
        cache.mark_multiple_as_sent([r.id for r in reports], "reports")
        cache.mark_multiple_as_sent([v.id for v in all_videos], "youtube")
        logger.info(f"Successfully sent {len(embeds)} embeds to Discord")
    else:
        logger.error("Failed to send to Discord")

    return success


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("=" * 50)
    logger.info("Market Rader Starting...")
    logger.info(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 50)

    # ì„¤ì • ê²€ì¦
    if not validate_settings():
        logger.error("Configuration validation failed. Exiting.")
        sys.exit(1)

    try:
        # 1. ì½˜í…ì¸  ìˆ˜ì§‘
        news = collect_news()  # {"korean": [...], "international": [...]}
        reports = collect_reports()
        videos = collect_youtube()

        # ìˆ˜ì§‘ëœ ì½˜í…ì¸ ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
        all_news = news.get("korean", []) + news.get("international", [])
        if not all_news and not reports and not videos:
            logger.info("No new content collected. Exiting.")
            return

        # 2. ë¶„ì„ ë° ìš”ì•½
        analyzed = analyze_content(news, reports, videos)

        # 3. Discord ì „ì†¡
        success = send_to_discord(analyzed)

        # 4. ìºì‹œ ì •ë¦¬
        cache.cleanup_old_entries(days=7)

        if success:
            logger.info("Market Rader completed successfully!")
        else:
            logger.warning("Market Rader completed with some errors")

    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise


if __name__ == "__main__":
    main()
