"""ì•„ì¹¨ ì „ëµ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜) - ì „ì²´ í•­ëª© í¬í•¨"""
import sys
from pathlib import Path

ROOT_DIR = Path(__file__).parent
sys.path.insert(0, str(ROOT_DIR))

from src.collectors.news import NaverFinanceNewsCollector, RSSNewsCollector
from src.collectors.reports import NaverResearchCollector, MorningBriefCollector
from src.collectors.youtube import YouTubeChannelMonitor
from src.discord.embeds.briefing_embed import create_morning_strategy_embed
from src.discord.embeds.news_embed import create_news_list_embeds
from src.discord.embeds.morning_brief_embed import create_morning_brief_embed
from src.discord.embeds.report_embed import (
    create_reports_with_analysis_embeds,
    create_reports_header_embed,
    create_reports_list_embed,
)
from src.discord.embeds.youtube_embed import create_youtube_list_embed
from src.analyzer.market_briefing import market_briefing_generator
from src.analyzer.briefing_validator import briefing_validator
from src.analyzer.importance_scorer import importance_scorer
from src.analyzer import morning_brief_summarizer, video_summarizer, report_analyzer
from src.discord import discord_sender
from config.settings import get_news_sources
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

if __name__ == "__main__":
    print("=" * 60)
    print("ì•„ì¹¨ ì „ëµ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸ (ì „ì²´ í•­ëª© í¬í•¨)")
    print("=" * 60)

    now = datetime.now()
    embeds = []

    # 1. í•œêµ­ ë‰´ìŠ¤ ìˆ˜ì§‘
    print("\n[1/7] í•œêµ­ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    news_collector = NaverFinanceNewsCollector(categories=["stock", "economy"], extract_journalist=True)
    korean_news = news_collector.collect()
    for item in korean_news:
        item.extra_data["region"] = "korean"
    print(f"  ìˆ˜ì§‘ëœ í•œêµ­ ë‰´ìŠ¤: {len(korean_news)}ê±´")

    # ê¸°ìëª… ì¶”ì¶œ í˜„í™©
    journalists_found = sum(1 for n in korean_news if n.extra_data.get("journalist"))
    print(f"  ê¸°ìëª… ì¶”ì¶œ: {journalists_found}ê±´")

    # 2. í•´ì™¸ ë‰´ìŠ¤ ìˆ˜ì§‘ (RSS)
    print("\n[2/7] í•´ì™¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    international_news = []
    news_config = get_news_sources()
    intl_sources = news_config.get("news", {}).get("international", [])

    for source in intl_sources[:5]:  # ìƒìœ„ 5ê°œ ì†ŒìŠ¤ë§Œ
        if source.get("type") == "rss" and source.get("enabled", True):
            try:
                collector = RSSNewsCollector(
                    name=source["name"],
                    url=source["url"],
                )
                items = collector.collect()
                for item in items:
                    item.extra_data["region"] = "international"
                international_news.extend(items)
                print(f"    - {source['name']}: {len(items)}ê±´")
            except Exception as e:
                print(f"    - {source['name']}: ì‹¤íŒ¨ ({e})")

    print(f"  ìˆ˜ì§‘ëœ í•´ì™¸ ë‰´ìŠ¤: {len(international_news)}ê±´")

    # 3. ë¦¬í¬íŠ¸ ìˆ˜ì§‘ (PDF ì¶”ì¶œ í¬í•¨)
    print("\n[3/7] ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì¤‘ (PDF ì¶”ì¶œ í¬í•¨)...")
    report_collector = NaverResearchCollector(
        categories=["invest", "company", "market"],
        extract_pdf=True,
        max_pdf_extract=8,  # ë” ë§ì€ ë¦¬í¬íŠ¸ ë¶„ì„ì„ ìœ„í•´ ì¦ê°€
    )
    report_items = report_collector.collect()
    print(f"  ìˆ˜ì§‘ëœ ë¦¬í¬íŠ¸: {len(report_items)}ê±´")

    # PDF ì¶”ì¶œëœ ë¦¬í¬íŠ¸ ìˆ˜
    pdf_extracted = sum(1 for r in report_items if r.extra_data.get("pdf_text"))
    print(f"  PDF ì¶”ì¶œ: {pdf_extracted}ê±´")

    # 4. Morning Brief ìˆ˜ì§‘
    print("\n[4/7] Morning Brief ìˆ˜ì§‘ ì¤‘...")
    try:
        brief_collector = MorningBriefCollector(max_briefs=3)
        morning_briefs = brief_collector.collect()
        print(f"  ìˆ˜ì§‘ëœ Morning Brief: {len(morning_briefs)}ê±´")
        for brief in morning_briefs[:3]:
            print(f"    - [{brief.source}] {brief.title[:40]}...")
    except Exception as e:
        print(f"  Morning Brief ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        morning_briefs = []

    # 5. ìœ íŠœë¸Œ ìˆ˜ì§‘
    print("\n[5/7] ìœ íŠœë¸Œ ì˜ìƒ ìˆ˜ì§‘ ì¤‘...")
    try:
        youtube_monitor = YouTubeChannelMonitor()
        videos = youtube_monitor.collect()
        korean_videos = videos.get("korean", [])[:5]
        intl_videos = videos.get("international", [])[:5]
        print(f"  í•œêµ­ ìœ íŠœë¸Œ: {len(korean_videos)}ê±´")
        print(f"  í•´ì™¸ ìœ íŠœë¸Œ: {len(intl_videos)}ê±´")
    except Exception as e:
        print(f"  ìœ íŠœë¸Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        korean_videos = []
        intl_videos = []

    # 6. ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
    print("\n[6/7] ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚° ì¤‘...")

    # í•œêµ­ ë‰´ìŠ¤
    scored_korean = importance_scorer.filter_by_importance(korean_news, min_score=0.3)
    top_korean = scored_korean[:15]

    # í•´ì™¸ ë‰´ìŠ¤
    scored_intl = importance_scorer.filter_by_importance(international_news, min_score=0.3)
    top_intl = scored_intl[:10]

    # ë¦¬í¬íŠ¸
    scored_reports = importance_scorer.score_batch(report_items)
    scored_reports.sort(key=lambda x: x.importance_score, reverse=True)
    top_reports = scored_reports[:10]

    # ìš°ì„  í•­ëª© í™•ì¸
    priority_journalist_count = sum(1 for n in top_korean if n.extra_data.get("is_priority_journalist_article"))
    priority_keyword_count = sum(1 for n in top_korean if n.extra_data.get("is_priority_keyword_match"))
    print(f"  í•œêµ­ ë‰´ìŠ¤ ìš°ì„  ê¸°ì: {priority_journalist_count}ê±´")
    print(f"  í•œêµ­ ë‰´ìŠ¤ ìš°ì„  í‚¤ì›Œë“œ: {priority_keyword_count}ê±´")

    print(f"\n  ìƒìœ„ 5ê°œ í•œêµ­ ë‰´ìŠ¤:")
    for i, item in enumerate(top_korean[:5], 1):
        journalist = item.extra_data.get("journalist", "")
        j_str = f" (ê¸°ì:{journalist})" if journalist else ""
        print(f"    {i}. [{item.importance_score:.2f}] {item.title[:35]}...{j_str}")

    print(f"\n  ìƒìœ„ 5ê°œ í•´ì™¸ ë‰´ìŠ¤:")
    for i, item in enumerate(top_intl[:5], 1):
        print(f"    {i}. [{item.importance_score:.2f}] {item.title[:45]}...")

    # 7. Embed ìƒì„±
    print("\n[7/7] Embed ìƒì„± ì¤‘...")

    all_news = top_korean[:10] + top_intl[:5]

    # 7-1. Morning Brief Embed (ê°œë³„ ë¶„ì„ í¬í•¨)
    if morning_briefs:
        # ê°œë³„ Morning Brief AI ë¶„ì„
        print("  Morning Brief ê°œë³„ ë¶„ì„ ì¤‘...")
        morning_briefs = morning_brief_summarizer.analyze_all_briefs(morning_briefs)
        analyzed_count = sum(1 for b in morning_briefs if b.extra_data.get("ai_analysis"))
        print(f"    ê°œë³„ ë¶„ì„ ì™„ë£Œ: {analyzed_count}ê±´")

        # ì¢…í•© ìš”ì•½
        combined_summary = morning_brief_summarizer.summarize_multiple_briefs(morning_briefs)
        brief_embeds = create_morning_brief_embed(morning_briefs, combined_summary, show_individual_analysis=True)
        embeds.extend(brief_embeds)
        print(f"  Morning Brief Embed: {len(brief_embeds)}ê°œ")

    # 7-2. AI ì•„ì¹¨ ì „ëµ ë¸Œë¦¬í•‘
    print("  AI ì•„ì¹¨ ì „ëµ ë¸Œë¦¬í•‘ ìƒì„± ì¤‘...")
    briefing = market_briefing_generator.generate_morning_strategy(
        news_items=all_news,
        morning_briefs=morning_briefs,
        report_items=top_reports[:5],
    )

    if briefing:
        print(f"    ì¸ì‚¬: {briefing.greeting[:50]}...")
        print(f"    ìš”ì•½: {briefing.summary[:60]}...")
        print(f"    ë¶„ìœ„ê¸°: {briefing.mood}")

        # ë¸Œë¦¬í•‘ ê²€ì¦
        briefing_text = briefing_validator.get_briefing_text(briefing)
        validation = briefing_validator.validate_briefing(
            briefing_text=briefing_text,
            market_data=None,
            news_items=all_news,
            report_items=top_reports[:5],
        )

        print(f"    ê²€ì¦ ì ìˆ˜: {validation.score}")
        print(f"    ê²€ì¦ í†µê³¼: {'O' if validation.is_valid else 'X'}")

        if validation.is_valid:
            strategy_embed = create_morning_strategy_embed(briefing, now)
            embeds.append(strategy_embed)
            print("  AI ì•„ì¹¨ ë¸Œë¦¬í•‘ Embed: 1ê°œ (ê²€ì¦ í†µê³¼)")
        else:
            print("  AI ë¸Œë¦¬í•‘ ê²€ì¦ ì‹¤íŒ¨ - ì „ì†¡í•˜ì§€ ì•ŠìŒ")
            for error in validation.errors:
                print(f"    ì˜¤ë¥˜: {error}")
    else:
        print("  AI ë¸Œë¦¬í•‘ ìƒì„± ì‹¤íŒ¨")

    # 7-3. í•œêµ­ ë‰´ìŠ¤ ëª©ë¡
    if top_korean:
        news_embeds = create_news_list_embeds(
            items=top_korean,
            title=f"ğŸ‡°ğŸ‡· êµ­ë‚´ ë‰´ìŠ¤ ({len(top_korean)}ê±´)",
            items_per_embed=5,
            color="e74c3c",
        )
        embeds.extend(news_embeds)
        print(f"  í•œêµ­ ë‰´ìŠ¤ Embed: {len(news_embeds)}ê°œ")

    # 7-4. í•´ì™¸ ë‰´ìŠ¤ ëª©ë¡
    if top_intl:
        intl_embeds = create_news_list_embeds(
            items=top_intl,
            title=f"ğŸ‡ºğŸ‡¸ í•´ì™¸ ë‰´ìŠ¤ ({len(top_intl)}ê±´)",
            items_per_embed=5,
            color="3498db",
        )
        embeds.extend(intl_embeds)
        print(f"  í•´ì™¸ ë‰´ìŠ¤ Embed: {len(intl_embeds)}ê°œ")

    # 7-5. ë¦¬í¬íŠ¸ ëª©ë¡
    if top_reports:
        # PDF ì¶”ì¶œëœ ë¦¬í¬íŠ¸ AI ë¶„ì„
        pdf_reports = [r for r in top_reports if r.extra_data.get("pdf_text")]
        if pdf_reports:
            try:
                report_analyzer.analyze_batch(pdf_reports, max_items=5)  # ë” ë§ì€ ë¦¬í¬íŠ¸ ë¶„ì„
                analyzed_count = sum(1 for r in pdf_reports if r.extra_data.get("ai_analysis"))
                print(f"  ë¦¬í¬íŠ¸ AI ë¶„ì„: {analyzed_count}ê±´")
            except Exception as e:
                print(f"  ë¦¬í¬íŠ¸ AI ë¶„ì„ ì‹¤íŒ¨: {e}")

        # AI ë¶„ì„ëœ ë¦¬í¬íŠ¸ê°€ ìˆìœ¼ë©´ ìƒì„¸ Embed
        analyzed_reports = [r for r in top_reports if r.extra_data.get("ai_analysis")]
        if analyzed_reports:
            report_embeds = create_reports_with_analysis_embeds(
                items=top_reports,
                max_detailed=3,
                max_list=7,
            )
            embeds.extend(report_embeds)
            print(f"  ë¦¬í¬íŠ¸ Embed (AI ë¶„ì„ í¬í•¨): {len(report_embeds)}ê°œ")
        else:
            # ê¸°ì¡´ ë°©ì‹
            reports_header = create_reports_header_embed(
                report_count=len(top_reports),
                summary=None,
            )
            embeds.append(reports_header)
            reports_list = create_reports_list_embed(
                items=top_reports,
                max_items=10,
            )
            embeds.append(reports_list)
            print(f"  ë¦¬í¬íŠ¸ Embed: 2ê°œ")

    # 7-6. ìœ íŠœë¸Œ ì˜ìƒ
    video_summaries = {}

    # ìœ íŠœë¸Œ ìš”ì•½ (ë³‘ë ¬)
    all_videos = korean_videos + intl_videos
    if all_videos:
        print("  ìœ íŠœë¸Œ ìš”ì•½ ìƒì„± ì¤‘...")
        for video in all_videos[:5]:  # ìƒìœ„ 5ê°œë§Œ
            try:
                summary = video_summarizer.summarize_video(video)
                if summary:
                    video_summaries[video.id] = summary
            except Exception as e:
                pass

    if korean_videos:
        korean_yt_embed = create_youtube_list_embed(
            items=korean_videos,
            title=f"ğŸ‡°ğŸ‡· í•œêµ­ ìœ íŠœë¸Œ ({len(korean_videos)}ê±´)",
            max_items=5,
            video_summaries=video_summaries,
        )
        embeds.append(korean_yt_embed)
        print(f"  í•œêµ­ ìœ íŠœë¸Œ Embed: 1ê°œ")

    if intl_videos:
        intl_yt_embed = create_youtube_list_embed(
            items=intl_videos,
            title=f"ğŸ‡ºğŸ‡¸ í•´ì™¸ ìœ íŠœë¸Œ ({len(intl_videos)}ê±´)",
            max_items=5,
            video_summaries=video_summaries,
        )
        embeds.append(intl_yt_embed)
        print(f"  í•´ì™¸ ìœ íŠœë¸Œ Embed: 1ê°œ")

    # 8. Discord ì „ì†¡
    print("\n" + "=" * 60)
    print(f"ì´ {len(embeds)}ê°œ Embed ìƒì„±ë¨")
    print("Discordë¡œ ì „ì†¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    choice = input().strip().lower()

    if choice == 'y' and embeds:
        print("ì „ì†¡ ì¤‘...")
        success = discord_sender.send_multiple_embeds(embeds)
        if success:
            print("ì „ì†¡ ì™„ë£Œ!")
        else:
            print("ì „ì†¡ ì‹¤íŒ¨")
    else:
        print("ì „ì†¡ ì·¨ì†Œë¨")

    print("=" * 60)
